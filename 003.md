下面是一个完整的 Terraform 示例脚本，包含创建 Lambda 函数所需的 IAM 角色、策略以及打包上传 Lambda 代码的逻辑。假设你的 Lambda 代码存放在同目录下的 **lambda_function.py** 文件中，Terraform 将通过 archive_file 数据源将其打包成 zip 文件，并作为 Lambda 函数的代码上传。

你可以将下面的内容保存为 main.tf 文件，并根据实际情况调整变量值：

```hcl
provider "aws" {
  region = "us-east-1"   # 根据需要调整区域
}

###############################
# 定义 Lambda 使用的 IAM 角色  #
###############################

resource "aws_iam_role" "lambda_exec_role" {
  name = "lambda_exec_role"
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action    = "sts:AssumeRole"
      Effect    = "Allow"
      Principal = {
        Service = "lambda.amazonaws.com"
      }
    }]
  })
}

# 附加 AWSLambdaBasicExecutionRole 策略，用于写 CloudWatch Logs
resource "aws_iam_role_policy_attachment" "lambda_basic" {
  role       = aws_iam_role.lambda_exec_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}

# 自定义策略，允许访问 S3（列举和读取）和提交 Batch 作业
resource "aws_iam_policy" "lambda_custom_policy" {
  name        = "lambda_custom_policy"
  description = "Policy for Lambda to access S3 and AWS Batch"
  policy      = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Effect   = "Allow"
        Action   = [
          "s3:ListBucket",
          "s3:GetObject"
        ]
        Resource = [
          "arn:aws:s3:::${var.s3_bucket}",
          "arn:aws:s3:::${var.s3_bucket}/*"
        ]
      },
      {
        Effect   = "Allow"
        Action   = [
          "batch:SubmitJob"
        ]
        Resource = "*"
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "lambda_custom_policy_attachment" {
  role       = aws_iam_role.lambda_exec_role.name
  policy_arn = aws_iam_policy.lambda_custom_policy.arn
}

#####################################
# 打包 Lambda 代码（lambda_function.py） #
#####################################

data "archive_file" "lambda_zip" {
  type        = "zip"
  source_file = "${path.module}/lambda_function.py"
  output_path = "${path.module}/lambda_function.zip"
}

#############################
# 创建 Lambda 函数资源      #
#############################

resource "aws_lambda_function" "untar_lambda" {
  function_name = "untar_lambda"
  role          = aws_iam_role.lambda_exec_role.arn
  handler       = "lambda_function.lambda_handler"
  runtime       = "python3.8"
  filename      = data.archive_file.lambda_zip.output_path

  environment {
    variables = {
      S3_BUCKET            = var.s3_bucket
      S3_PREFIX            = var.s3_prefix
      BATCH_JOB_DEFINITION = var.batch_job_definition
      BATCH_JOB_QUEUE      = var.batch_job_queue
    }
  }
}

#############################
# 变量定义                   #
#############################

variable "s3_bucket" {
  description = "存放 tar.gz 文件的 S3 桶名称"
  type        = string
}

variable "s3_prefix" {
  description = "S3 桶中 tar.gz 文件的前缀（如果有）"
  type        = string
  default     = ""
}

variable "batch_job_definition" {
  description = "AWS Batch 作业定义名称"
  type        = string
}

variable "batch_job_queue" {
  description = "AWS Batch 作业队列名称"
  type        = string
}

#############################
# 输出 Lambda ARN          #
#############################

output "lambda_function_arn" {
  description = "创建的 Lambda 函数 ARN"
  value       = aws_lambda_function.untar_lambda.arn
}
```

---

### 说明

1. **IAM 角色与权限**  
   - 通过资源 `aws_iam_role.lambda_exec_role` 定义 Lambda 执行角色，并附加基础的 CloudWatch Logs 权限。  
   - 自定义策略 `aws_iam_policy.lambda_custom_policy` 授权 Lambda 函数列举 S3 桶中的对象、读取对象以及提交 AWS Batch 作业。

2. **代码打包**  
   - 使用数据源 `archive_file` 将当前目录下的 **lambda_function.py** 文件打包为 zip 文件，并作为 Lambda 代码上传。

3. **Lambda 函数创建**  
   - `aws_lambda_function.untar_lambda` 资源定义了 Lambda 函数，指定了运行环境、处理器、代码包以及所需的环境变量（S3_BUCKET、S3_PREFIX、BATCH_JOB_DEFINITION、BATCH_JOB_QUEUE）。

4. **变量设置**  
   - 通过变量定义可以在 terraform apply 时传入实际的 S3 桶名称、前缀、Batch 作业定义名称以及作业队列名称。

保存好 main.tf 后，运行以下命令初始化并应用 Terraform 配置：

```bash
terraform init
terraform apply
```

完成后，Terraform 会创建所需的资源并输出 Lambda 函数的 ARN。
