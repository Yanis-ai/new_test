为了创建上述架构和流程，使用 Terraform 实现每个部分的资源创建及脚本，我们需要分别创建和配置 S3、ECR、ECS、Lambda、AWS Batch 等服务，以及一些 Docker 和 Python 脚本。接下来是整体的代码结构及每个文件的详细代码。

### 项目目录结构

```
terraform_project/
│
├── main.tf                 # Terraform 主配置文件
├── variables.tf            # Terraform 变量文件
├── outputs.tf              # Terraform 输出配置
│
├── s3/
│   └── s3_bucket.tf        # 创建 S3 Bucket
│
├── ecr/
│   └── ecr_repository.tf   # 创建 ECR 镜像仓库
│   └── dockerfile          # Dockerfile 用于解压 tar.gz 文件
│
├── ecs/
│   └── ecs_cluster.tf      # 创建 ECS 集群
│   └── ecs_service.tf      # 创建 ECS 服务
│   └── ecs_task_definition.tf # 创建 ECS 任务定义
│
├── lambda/
│   ├── lambda_function.tf  # 创建 Lambda 函数
│   └── check_file_lambda.py # 用于检查文件数量的 Python 脚本
│
├── batch/
│   └── batch_job.tf        # 创建 AWS Batch 相关资源
│   └── batch_compute_env.tf # 创建 Batch 计算环境
│   └── batch_job_queue.tf  # 创建 Batch 作业队列
│   └── batch_job_def.tf    # 创建 Batch 作业定义
│
└── scripts/
    └── create_tar_gz.sh    # 脚本用于上传多个 tar.gz 文件到 S3
    └── invoke_lambda.sh    # 脚本用于调用 Lambda
```

### 1. Terraform 创建 S3 Bucket

`s3/s3_bucket.tf`:

```hcl
resource "aws_s3_bucket" "input_bucket" {
  bucket = "my-input-bucket"
  region = "ap-northeast-1"
}

resource "aws_s3_bucket" "output_bucket" {
  bucket = "my-output-bucket"
  region = "ap-northeast-1"
}
```

### 2. Terraform 创建脚本上传 tar.gz 文件到 S3

`scripts/create_tar_gz.sh`:

```bash
#!/bin/bash

# 这里你可以动态地创建多个 tar.gz 文件，假设我们有一个 input 目录
for file in input/*.tar.gz
do
  aws s3 cp "$file" s3://my-input-bucket/
done
```

### 3. Terraform 创建 ECR 仓库和 Dockerfile

`ecr/ecr_repository.tf`:

```hcl
resource "aws_ecr_repository" "tar_gz_processor" {
  name = "tar-gz-processor"
}
```

`ecr/dockerfile`:

```dockerfile
# 使用 Python 镜像作为基础镜像
FROM python:3.9-slim

# 设置工作目录
WORKDIR /app

# 复制并安装解压 tar.gz 文件的依赖
COPY requirements.txt .
RUN pip install -r requirements.txt

# 复制 Python 解压脚本
COPY extract.py .

# 设置入口命令
CMD ["python", "extract.py"]
```

### 4. Terraform 创建 ECS 集群和服务

`ecs/ecs_cluster.tf`:

```hcl
resource "aws_ecs_cluster" "tar_gz_cluster" {
  name = "tar-gz-cluster"
}
```

`ecs/ecs_service.tf`:

```hcl
resource "aws_ecs_service" "tar_gz_service" {
  name            = "tar-gz-service"
  cluster         = aws_ecs_cluster.tar_gz_cluster.id
  task_definition = aws_ecs_task_definition.tar_gz_task_definition.arn
  desired_count   = 1
}
```

`ecs/ecs_task_definition.tf`:

```hcl
resource "aws_ecs_task_definition" "tar_gz_task_definition" {
  family                   = "tar-gz-task"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = "256"
  memory                   = "512"
  execution_role_arn       = aws_iam_role.ecs_execution_role.arn
  task_role_arn            = aws_iam_role.ecs_task_role.arn

  container_definitions = jsonencode([{
    name      = "tar-gz-container"
    image     = aws_ecr_repository.tar_gz_processor.repository_url
    essential = true
    memory    = 512
    cpu       = 256
  }])
}
```

### 5. Terraform 创建 Lambda 函数

`lambda/lambda_function.tf`:

```hcl
resource "aws_lambda_function" "check_file_lambda" {
  filename      = "lambda_function.zip"
  function_name = "check-file-lambda"
  role          = aws_iam_role.lambda_role.arn
  handler       = "check_file_lambda.lambda_handler"
  runtime       = "python3.8"
  timeout       = 300
}

resource "aws_iam_role" "lambda_role" {
  name = "lambda-role"
  assume_role_policy = jsonencode({
    "Version" : "2012-10-17",
    "Statement" : [
      {
        "Action" : "sts:AssumeRole",
        "Effect" : "Allow",
        "Principal" : {
          "Service" : "lambda.amazonaws.com"
        }
      }
    ]
  })
}
```

`lambda/check_file_lambda.py`:

```python
import json
import boto3

s3_client = boto3.client('s3')

def lambda_handler(event, context):
    bucket_name = event['bucket']
    prefix = event['prefix']
    
    # 列出 S3 中的文件
    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
    
    files = response.get('Contents', [])
    file_count = len(files)
    
    # 返回文件数量
    return {
        'statusCode': 200,
        'body': json.dumps({'file_count': file_count})
    }
```

### 6. Terraform 创建 AWS Batch 资源

`batch/batch_job.tf`:

```hcl
resource "aws_batch_job_definition" "tar_gz_job" {
  name = "tar-gz-job"
  type = "container"

  container_properties = jsonencode({
    image: aws_ecr_repository.tar_gz_processor.repository_url,
    vcpus: 1,
    memory: 2048,
    command: ["python", "extract.py"],
    jobRoleArn: aws_iam_role.batch_job_role.arn
  })
}
```

`batch/batch_compute_env.tf`:

```hcl
resource "aws_batch_compute_environment" "tar_gz_compute_env" {
  compute_environment_name = "tar-gz-compute-env"
  type                     = "MANAGED"
  state                    = "ENABLED"

  compute_resources {
    type             = "EC2"
    min_vcpus        = 1
    max_vcpus        = 16
    instance_types   = ["optimal"]
    subnets          = ["subnet-abc123"]
    security_group_ids = ["sg-abc123"]
  }
}
```

`batch/batch_job_queue.tf`:

```hcl
resource "aws_batch_job_queue" "tar_gz_job_queue" {
  job_queue_name = "tar-gz-job-queue"
  state          = "ENABLED"
  priority       = 1
  compute_environment_order {
    order = 1
    compute_environment = aws_batch_compute_environment.tar_gz_compute_env.arn
  }
}
```

### 7. Terraform 创建脚本调用 Lambda

`scripts/invoke_lambda.sh`:

```bash
#!/bin/bash

# 调用 Lambda 函数，传入 S3 存储桶名和文件前缀
aws lambda invoke \
  --function-name check-file-lambda \
  --payload '{"bucket": "my-input-bucket", "prefix": "input/"}' \
  output.json

# 打印输出
cat output.json
```

### 总结

上面是创建这些资源和服务的基本 Terraform 配置文件，涵盖了 S3 存储、ECR 镜像仓库、ECS、Lambda、AWS Batch 等服务的创建。对于文件处理、并发解压等逻辑的实现，可以根据需求调整 Lambda 和 Python 脚本的细节。
