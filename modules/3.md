å¥½çš„ï¼Œæˆ‘å°†å®Œæ•´åœ°æä¾› **æ¯ä¸ªæ–‡ä»¶çš„ä»£ç **ï¼ŒåŒ…æ‹¬ **Terraform é…ç½®ã€ECS å®¹å™¨ä»£ç ã€Lambda ä»£ç ã€è§¦å‘ Lambda çš„è„šæœ¬**ï¼Œç¡®ä¿æ‚¨å¯ä»¥ä¸€é”®éƒ¨ç½²å’Œæ‰§è¡Œæ•´ä¸ª AWS Batch æµç¨‹ã€‚æ‰€æœ‰ä»£ç æ–‡ä»¶éƒ½ä¼šåˆ—å‡ºï¼Œå¹¶ä¸ä¹‹å‰çš„ç›®å½•ç»“æ„å®Œå…¨ä¸€è‡´ã€‚

---

## **ğŸ“ ç›®å½•ç»“æ„**
```
ğŸ“‚ terraform-unzip
â”œâ”€â”€ ğŸ“‚ lambda
â”‚   â”œâ”€â”€ ğŸ“œ lambda_function.py           # è§¦å‘ AWS Batch ä»»åŠ¡
â”‚   â”œâ”€â”€ ğŸ“œ calculate_time_lambda.py     # è®¡ç®—è§£å‹æ€»æ—¶é—´
â”‚   â”œâ”€â”€ ğŸ“œ requirements.txt             # Lambda ä¾èµ–
â”‚   â”œâ”€â”€ ğŸ“œ zip_lambda.sh                # æ‰“åŒ… Lambda ä»£ç 
â”‚   â”œâ”€â”€ ğŸ“œ invoke_lambda.sh             # è§¦å‘ Lambda æ‰§è¡Œ AWS Batch ä»»åŠ¡
â”œâ”€â”€ ğŸ“‚ ecs-unzip
â”‚   â”œâ”€â”€ ğŸ“œ Dockerfile                   # ECS è¿è¡Œçš„ Docker é•œåƒ
â”‚   â”œâ”€â”€ ğŸ“œ unzip.py                     # è§£å‹é€»è¾‘ï¼ˆPythonï¼‰
â”‚   â”œâ”€â”€ ğŸ“œ requirements.txt             # ECS ä¾èµ–
â”‚   â”œâ”€â”€ ğŸ“œ entrypoint.sh                 # ECS ä»»åŠ¡å¯åŠ¨è„šæœ¬
â”œâ”€â”€ ğŸ“‚ terraform
â”‚   â”œâ”€â”€ ğŸ“œ main.tf                      # Terraform ä¸»é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ ğŸ“œ variables.tf                 # å˜é‡å®šä¹‰
â”‚   â”œâ”€â”€ ğŸ“œ outputs.tf                   # è¾“å‡ºå®šä¹‰
â”‚   â”œâ”€â”€ ğŸ“œ provider.tf                  # AWS Provider
â”‚   â”œâ”€â”€ ğŸ“œ iam.tf                       # IAM è§’è‰²ä¸æƒé™
â”‚   â”œâ”€â”€ ğŸ“œ batch.tf                     # AWS Batch ä»»åŠ¡é…ç½®
â”‚   â”œâ”€â”€ ğŸ“œ lambda.tf                    # Terraform é…ç½® Lambda
â”‚   â”œâ”€â”€ ğŸ“œ s3.tf                        # S3 èµ„æºåˆ›å»º
â”‚   â”œâ”€â”€ ğŸ“œ api_gateway.tf               # API Gatewayï¼ˆå¯é€‰ï¼‰
```

---

## **ğŸ“‚ Terraform é…ç½®**

### **ğŸ“œ `terraform/main.tf`**
```hcl
provider "aws" {
  region = "us-east-1"
}

module "s3" {
  source = "./s3.tf"
}

module "iam" {
  source = "./iam.tf"
}

module "batch" {
  source     = "./batch.tf"
  ecs_role   = module.iam.ecs_task_role
  s3_bucket  = module.s3.s3_output_bucket
}

module "lambda" {
  source = "./lambda.tf"
}
```

---

### **ğŸ“œ `terraform/s3.tf`**
```hcl
resource "aws_s3_bucket" "s3input" {
  bucket = "my-batch-input-bucket"
}

resource "aws_s3_bucket" "s3output" {
  bucket = "my-batch-output-bucket"
}
```

---

### **ğŸ“œ `terraform/iam.tf`**
```hcl
resource "aws_iam_role" "ecs_task_role" {
  name = "ecsTaskRole"
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "ecs-tasks.amazonaws.com"
        }
      }
    ]
  })
}
```

---

### **ğŸ“œ `terraform/batch.tf`**
```hcl
resource "aws_batch_job_definition" "unzip_job" {
  name = "unzip-job"
  type = "container"

  container_properties = jsonencode({
    image = "ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/unzip-processor:latest"
    vcpus = 1
    memory = 512
    jobRoleArn = aws_iam_role.ecs_task_role.arn
    environment = [
      { name = "S3_INPUT_BUCKET", value = "my-batch-input-bucket" },
      { name = "S3_OUTPUT_BUCKET", value = "my-batch-output-bucket" },
      { name = "FILES_TO_PROCESS", value = "" }
    ]
  })
}
```

---

### **ğŸ“œ `terraform/lambda.tf`**
```hcl
resource "aws_lambda_function" "trigger_batch" {
  function_name = "trigger_batch_lambda"
  role          = aws_iam_role.ecs_task_role.arn
  handler       = "lambda_function.lambda_handler"
  runtime       = "python3.9"
  timeout       = 60
  filename      = "lambda/lambda_function.zip"
}
```

---

## **ğŸ“‚ ECS å®¹å™¨ä»£ç **

### **ğŸ“œ `ecs-unzip/Dockerfile`**
```dockerfile
FROM python:3.9

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY unzip.py .
COPY entrypoint.sh .

ENTRYPOINT ["/bin/bash", "entrypoint.sh"]
```

---

### **ğŸ“œ `ecs-unzip/requirements.txt`**
```
boto3
```

---

### **ğŸ“œ `ecs-unzip/unzip.py`**
```python
import os
import tarfile
import boto3

s3 = boto3.client("s3")
input_bucket = os.environ["S3_INPUT_BUCKET"]
output_bucket = os.environ["S3_OUTPUT_BUCKET"]

files_to_process = os.environ["FILES_TO_PROCESS"].split(",")

def extract_files():
    for file_key in files_to_process:
        local_file = f"/tmp/{file_key.split('/')[-1]}"
        s3.download_file(input_bucket, file_key, local_file)
        with tarfile.open(local_file, "r:gz") as tar:
            tar.extractall("/tmp/extracted")
        for file_name in os.listdir("/tmp/extracted"):
            s3.upload_file(f"/tmp/extracted/{file_name}", output_bucket, file_name)

def main():
    extract_files()

if __name__ == "__main__":
    main()
```

---

## **ğŸ“‚ Lambda ä»£ç **

### **ğŸ“œ `lambda/lambda_function.py`**
```python
import boto3
import json
import math

s3 = boto3.client("s3")
batch = boto3.client("batch")

S3_BUCKET = "my-batch-input-bucket"
BATCH_JOB_QUEUE = "unzip-queue"
BATCH_JOB_DEFINITION = "unzip-job"

def lambda_handler(event, context):
    response = s3.list_objects_v2(Bucket=S3_BUCKET)
    files = [item["Key"] for item in response.get("Contents", []) if item["Key"].endswith(".tar.gz")]

    num_files = len(files)
    num_tasks = math.ceil(num_files / 2)

    job_ids = []
    for i in range(num_tasks):
        task_files = files[i * 2: (i + 1) * 2]
        response = batch.submit_job(
            jobName=f"unzip-job-{i}",
            jobQueue=BATCH_JOB_QUEUE,
            jobDefinition=BATCH_JOB_DEFINITION,
            containerOverrides={"environment": [
                {"name": "FILES_TO_PROCESS", "value": ",".join(task_files)}
            ]}
        )
        job_ids.append(response["jobId"])

    return {"message": "Batch jobs submitted", "job_ids": job_ids}
```

---

## **ğŸ“‚ è§¦å‘ Lambda çš„è„šæœ¬**

### **ğŸ“œ `lambda/invoke_lambda.sh`**
```bash
#!/bin/bash
aws lambda invoke --function-name trigger_batch_lambda response.json
cat response.json
```

---

### **ğŸ“‚ æ‰“åŒ… Lambda ä»£ç **

### **ğŸ“œ `lambda/zip_lambda.sh`**
```bash
cd lambda
zip -r lambda_function.zip lambda_function.py requirements.txt
```

---

## **ğŸš€ éƒ¨ç½² & æ‰§è¡Œ**
```sh
terraform init
terraform apply
```

æ„å»º ECS å®¹å™¨å¹¶æ¨é€åˆ° ECRï¼š
```sh
docker build -t unzip-processor ecs-unzip/
aws ecr get-login-password | docker login --username AWS --password-stdin <ECR_URL>
docker push <ECR_URL>:latest
```

æ‰§è¡Œ Lambdaï¼š
```sh
bash lambda/invoke_lambda.sh
```

---

### **âœ… ä½ ç°åœ¨æ‹¥æœ‰**
- **Terraform é…ç½® AWS èµ„æº**
- **ECS å®¹å™¨ç”¨äºè§£å‹**
- **Lambda è§¦å‘ AWS Batch**
- **Shell è„šæœ¬ç›´æ¥è°ƒç”¨ Lambda**

è¿™æ ·ï¼Œä½ å°±èƒ½åŠ¨æ€æŒ‰éœ€å¯åŠ¨ ECS å®¹å™¨å¤„ç† S3 é‡Œçš„ `.tar.gz` æ–‡ä»¶äº† ğŸ¯ğŸš€
