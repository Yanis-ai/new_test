是的，你可以 **减小 `VCPU` 和 `MEMORY`**，但要确保它们仍然足够支撑 `untar.py` 运行所需的计算资源。以下是你的 AWS Batch 任务对 CPU 和内存的要求：

### **1. 如何确定资源是否足够？**
你的 `untar.py` 主要执行：
- 下载 `.tar.gz` 文件
- 解压 `.tar.gz`
- 将文件上传到 S3

**主要消耗资源的部分：**
- **CPU**：解压 `.tar.gz` 可能会占用一定 CPU 资源，但不会太高，`0.5 VCPU` 可能就够了。
- **内存**：如果 `.tar.gz` 文件比较大，解压可能需要一定的 RAM。目前 `2048 MB`（2GB）是一个相对较大的值，**如果文件较小**，你可以减少内存。

---

### **2. 推荐的优化**
你可以调整如下：
```hcl
resourceRequirements = [
  {
    type  = "VCPU",
    value = "0.5"  # 降低 vCPU
  },
  {
    type  = "MEMORY",
    value = "1024"  # 降低内存
  }
]
```
### **3. 进一步优化**
如果 `.tar.gz` 文件通常很小（< 50MB），你可以尝试：
```hcl
resourceRequirements = [
  {
    type  = "VCPU",
    value = "0.25"  # 最低 0.25 vCPU
  },
  {
    type  = "MEMORY",
    value = "512"  # 最低 512MB
  }
]
```
但**如果解压 `.tar.gz` 需要大量 RAM**（例如 >500MB 的压缩文件），建议至少 **1GB RAM**，否则可能会导致 OOM（内存不足）。

---

### **4. 如何测试最小资源？**
可以先从 `0.5 VCPU` & `1024 MB` 开始：
```hcl
resourceRequirements = [
  {
    type  = "VCPU",
    value = "0.5"
  },
  {
    type  = "MEMORY",
    value = "1024"
  }
]
```
然后运行 AWS Batch 任务，观察：
- **运行时间**：如果任务变慢了，可能 CPU 需要增加。
- **失败情况**：如果任务因 `Out of Memory (OOM)` 失败，增加内存。

---

### **5. 结论**
| VCPU | MEMORY | 适用情况 |
|------|--------|---------|
| **1** | **2048MB** | 当前配置，适用于 **大文件解压** |
| **0.5** | **1024MB** | 适用于 **中等大小文件（50MB-500MB）** |
| **0.25** | **512MB** | 适用于 **小文件（<50MB）**，但可能 OOM |

你可以尝试 `0.5 vCPU` 和 `1024MB`，如果可以运行就保持这个配置，否则再调整！ 🚀



好的，我将为你的 Terraform 脚本中的资源添加合理的 `depends_on` 依赖，以确保 Terraform 在正确的顺序中创建资源，避免潜在的依赖问题。以下是经过优化的 **完整 Terraform 脚本**：

---

### **优化点**
✅ **保证 AWS Batch 任务执行前，S3、IAM 角色、ECR 镜像等资源已存在**  
✅ **确保 Lambda 角色在创建前 IAM 角色和策略已经绑定**  
✅ **避免 `terraform apply` 时遇到资源未创建的错误**  

---

### **修正后的 Terraform 脚本**
```hcl
#############################
# Provider 及变量定义       #
#############################

variable "aws_region" {
  description = "AWS Region"
  type        = string
  default     = "ap-northeast-1"
}

provider "aws" {
  region = var.aws_region
}

variable "lambda_runtime" {
  description = "Lambda 运行时环境"
  type        = string
  default     = "python3.9"
}

variable "batch_job_queue_name" {
  description = "AWS Batch 作业队列名称"
  type        = string
  default     = "untar-job-queue"
}

variable "batch_job_definition_name" {
  description = "AWS Batch 作业定义名称"
  type        = string
  default     = "untar-job-definition"
}

variable "test_prefix" {
  description = "バッチテスト環境のプレフィックス"
  type        = string
  default     = "batch-test"
}

#############################
# VPC 模块                   #
#############################
module "vpc" {
  source      = "./modules/vpc"
  test_prefix = var.test_prefix
}

#############################
# 随机后缀（用于 S3 桶名称）  #
#############################
resource "random_string" "suffix" {
  length  = 8
  special = false
  upper   = false
}

#############################
# S3 桶（输入文件存储）      #
#############################
resource "aws_s3_bucket" "s3input" {
  bucket        = "batch-bucket-${random_string.suffix.result}"
  force_destroy = true
}

#############################
# ECR 仓库（存放解压容器镜像）#
#############################
resource "aws_ecr_repository" "untar_repo" {
  name         = "untar-repo"
  force_delete = true
}

#############################
# Lambda 代码打包            #
#############################
data "archive_file" "lambda_zip" {
  type        = "zip"
  source_file = "${path.module}/lambda_function.py"
  output_path = "${path.module}/lambda_function.zip"
}

#############################
# Lambda 执行角色与权限       #
#############################
resource "aws_iam_role" "lambda_exec_role" {
  name = "lambda_exec_role"
  assume_role_policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [{
      Action    = "sts:AssumeRole",
      Effect    = "Allow",
      Principal = { Service = "lambda.amazonaws.com" }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "lambda_basic" {
  role       = aws_iam_role.lambda_exec_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"

  depends_on = [aws_iam_role.lambda_exec_role]
}

resource "aws_iam_policy" "lambda_custom_policy" {
  name   = "lambda_custom_policy"
  policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [
      {
        Effect = "Allow",
        Action = [
          "s3:ListBucket",
          "s3:GetObject",
          "s3:PutObject"
        ],
        Resource = [
          aws_s3_bucket.s3input.arn,
          "${aws_s3_bucket.s3input.arn}/*"
        ]
      },
      {
        Effect   = "Allow",
        Action   = [ "batch:SubmitJob" ],
        Resource = "*"
      }
    ]
  })

  depends_on = [aws_s3_bucket.s3input]
}

resource "aws_iam_role_policy_attachment" "lambda_custom_policy_attachment" {
  role       = aws_iam_role.lambda_exec_role.name
  policy_arn = aws_iam_policy.lambda_custom_policy.arn

  depends_on = [aws_iam_policy.lambda_custom_policy]
}

#############################
# Lambda 函数                #
#############################
resource "aws_lambda_function" "untar_lambda" {
  function_name = "untar_lambda"
  role          = aws_iam_role.lambda_exec_role.arn
  handler       = "lambda_function.lambda_handler"
  runtime       = var.lambda_runtime
  filename      = data.archive_file.lambda_zip.output_path
  timeout       = 900
  memory_size   = 512

  environment {
    variables = {
      S3_BUCKET            = aws_s3_bucket.s3input.id
      BATCH_JOB_DEFINITION = var.batch_job_definition_name
      BATCH_JOB_QUEUE      = var.batch_job_queue_name
    }
  }

  depends_on = [aws_iam_role_policy_attachment.lambda_custom_policy_attachment]
}

#############################
# AWS Batch 资源           #
#############################
resource "aws_batch_compute_environment" "batch_compute_env" {
  compute_environment_name = "batch_compute_env"
  service_role             = aws_iam_role.batch_service_role.arn
  type                     = "MANAGED"

  compute_resources {
    type              = "EC2"
    instance_role     = aws_iam_instance_profile.batch_instance_profile.arn
    instance_type     = [ "a1.medium" ]
    min_vcpus         = 0
    max_vcpus         = 2
    desired_vcpus     = 1
    subnets           = module.vpc.subnet_ids
    security_group_ids = [aws_security_group.batch_sg.id]
  }

  depends_on = [aws_iam_role.batch_service_role, aws_iam_instance_profile.batch_instance_profile]
}

resource "aws_batch_job_queue" "batch_job_queue" {
  name     = var.batch_job_queue_name
  state    = "ENABLED"
  priority = 1

  compute_environment_order {
    order               = 1
    compute_environment = aws_batch_compute_environment.batch_compute_env.arn
  }

  depends_on = [aws_batch_compute_environment.batch_compute_env]
}

resource "aws_batch_job_definition" "untar_job_definition" {
  name = var.batch_job_definition_name
  type = "container"

  container_properties = jsonencode({
    image            = "${aws_ecr_repository.untar_repo.repository_url}:latest",
    command          = [
      "python",
      "untar.py",
      "--bucket",
      "Ref::bucket",
      "--files",
      "Ref::files"
    ],
    executionRoleArn = aws_iam_role.ecs_execution_role.arn,
    resourceRequirements = [
      {
        type  = "VCPU",
        value = "0.5"
      },
      {
        type  = "MEMORY",
        value = "1024"
      }
    ]
  })

  parameters = {
    bucket = ""
    files  = ""
  }

  depends_on = [aws_batch_job_queue.batch_job_queue, aws_ecr_repository.untar_repo]
}
```

---

### **关键 `depends_on` 依赖调整**
1. **Lambda 依赖 IAM 角色和策略**
   - `aws_lambda_function.untar_lambda` **依赖 IAM 角色和策略已附加**
   - `aws_iam_policy.lambda_custom_policy` **依赖 S3 存在**

2. **Batch 计算环境**
   - `aws_batch_compute_environment` **依赖 IAM 角色**
   - `aws_batch_job_queue` **依赖 `batch_compute_env`**
   - `aws_batch_job_definition` **依赖 `aws_batch_job_queue` 和 `ECR`**

3. **ECR 镜像**  
   - 确保 `aws_batch_job_definition` 在 ECR 之后创建，以防 `image` 为空

---

### **优化后的 Terraform 优势**
✅ **确保 Lambda 只有在 IAM 权限完全配置后才会创建**  
✅ **Batch 计算环境不会提前创建，避免资源缺失错误**  
✅ **减少 `terraform apply` 失败风险，确保所有依赖正确**  

**这样 Terraform 运行起来会更稳定，更少出错！🚀**
