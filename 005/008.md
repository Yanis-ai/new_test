下面给出修改后的完整 Terraform 代码示例，该示例将 AWS Batch 计算环境改为 EC2 模式，并使用最小实例类型（此处采用 t3.micro），同时新增了 EC2 实例角色及实例配置（instance profile）。注意：其它部分保持不变，只针对 Batch 部分做了修改。

```hcl
#############################
# Provider 及变量定义       #
#############################

variable "aws_region" {
  description = "AWS Region"
  type        = string
  default     = "ap-northeast-1"
}

provider "aws" {
  # AWSリージョンを設定
  region = var.aws_region
}

variable "lambda_runtime" {
  description = "Lambda 运行时环境"
  type        = string
  default     = "python3.9"
}

variable "batch_job_queue_name" {
  description = "AWS Batch 作业队列名称"
  type        = string
  default     = "untar-job-queue"
}

variable "batch_job_definition_name" {
  description = "AWS Batch 作业定义名称"
  type        = string
  default     = "untar-job-definition"
}

variable "test_prefix" {
  description = "バッチテスト環境のプレフィックス"
  type        = string
  default     = "batch-test"
}

#############################
# VPC 模块                   #
#############################
module "vpc" {
  source      = "./modules/vpc"
  test_prefix = var.test_prefix
}

#############################
# 随机后缀（用于 S3 桶名称）  #
#############################
resource "random_string" "suffix" {
  length  = 8
  special = false
  upper   = false
}

#############################
# S3 桶（输入文件存储）      #
#############################
resource "aws_s3_bucket" "s3input" {
  bucket        = "batch-bucket-${random_string.suffix.result}"
  force_destroy = true
}

#############################
# ECR 仓库（存放解压容器镜像）#
#############################
resource "aws_ecr_repository" "untar_repo" {
  depends_on   = [ aws_s3_bucket.s3input ]
  name         = "untar-repo"
  force_delete = true
}

#############################
# Lambda 代码打包            #
#############################
data "archive_file" "lambda_zip" {
  type        = "zip"
  source_file = "${path.module}/lambda_function.py"
  output_path = "${path.module}/lambda_function.zip"
}

#############################
# Lambda 执行角色与权限       #
#############################
resource "aws_iam_role" "lambda_exec_role" {
  depends_on = [ aws_ecr_repository.untar_repo ]
  name       = "lambda_exec_role"
  assume_role_policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [{
      Action    = "sts:AssumeRole",
      Effect    = "Allow",
      Principal = { Service = "lambda.amazonaws.com" }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "lambda_basic" {
  depends_on = [ aws_iam_role.lambda_exec_role ]
  role       = aws_iam_role.lambda_exec_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}

resource "aws_iam_policy" "lambda_custom_policy" {
  depends_on = [ aws_iam_role_policy_attachment.lambda_basic ]
  name       = "lambda_custom_policy"
  policy     = jsonencode({
    Version   = "2012-10-17",
    Statement = [
      {
        Effect = "Allow",
        Action = [
          "s3:ListBucket",
          "s3:GetObject"
        ],
        Resource = [
          aws_s3_bucket.s3input.arn,
          "${aws_s3_bucket.s3input.arn}/*"
        ]
      },
      {
        Effect   = "Allow",
        Action   = [ "batch:SubmitJob" ],
        Resource = "*"
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "lambda_custom_policy_attachment" {
  role       = aws_iam_role.lambda_exec_role.name
  policy_arn = aws_iam_policy.lambda_custom_policy.arn
}

#############################
# 本地脚本执行及文件上传      #
#############################
resource "null_resource" "execute_and_upload" {
  depends_on = [ aws_s3_bucket.s3input ]
  provisioner "local-exec" {
    command = <<EOT
      ./00_generate_and_upload_script.sh
      aws s3 cp ./testfiles/ s3://${aws_s3_bucket.s3input.bucket}/input/ --recursive
      rm -f ./testfiles/*
      ./01_push_docker_to_ecr.sh
    EOT
  }
}

#############################
# Lambda 函数                #
#############################
resource "aws_lambda_function" "untar_lambda" {
  function_name = "untar_lambda"
  role          = aws_iam_role.lambda_exec_role.arn
  handler       = "lambda_function.lambda_handler"
  runtime       = var.lambda_runtime
  filename      = data.archive_file.lambda_zip.output_path
  timeout       = 900
  memory_size   = 512

  environment {
    variables = {
      S3_BUCKET            = aws_s3_bucket.s3input.id
      BATCH_JOB_DEFINITION = var.batch_job_definition_name
      BATCH_JOB_QUEUE      = var.batch_job_queue_name
    }
  }
}

resource "aws_lambda_permission" "s3_lambda" {
  statement_id  = "AllowS3InvokeLambda"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.untar_lambda.function_name
  principal     = "s3.amazonaws.com"
  source_arn    = aws_s3_bucket.s3input.arn
}

#############################
# AWS Batch 相关 IAM         #
#############################
# Batch 服务角色
resource "aws_iam_role" "batch_service_role" {
  name = "batch_service_role"
  assume_role_policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [{
      Effect    = "Allow",
      Principal = { Service = "batch.amazonaws.com" },
      Action    = "sts:AssumeRole"
    }]
  })
}

resource "aws_iam_role_policy_attachment" "batch_service_policy_attachment" {
  role       = aws_iam_role.batch_service_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSBatchServiceRole"
}

# 可选：批处理服务自定义策略（例如授权 ECS 相关操作）
resource "aws_iam_policy" "batch_service_custom_policy" {
  name   = "batch_service_custom_policy"
  policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [
      {
        Effect   = "Allow",
        Action   = [ "ecs:*" ],
        Resource = "*"
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "batch_service_custom_policy_attachment" {
  role       = aws_iam_role.batch_service_role.name
  policy_arn = aws_iam_policy.batch_service_custom_policy.arn
}

# ECS 任务执行角色（用于 Batch Job 定义中的 container pull）
resource "aws_iam_role" "ecs_execution_role" {
  name = "ecs-exection-role"
  assume_role_policy = jsonencode({
    Version = "2012-10-17",
    Statement = [{
      Effect    = "Allow",
      Principal = { Service = "ecs-tasks.amazonaws.com" },
      Action    = "sts:AssumeRole"
    }]
  })
}

resource "aws_iam_role_policy_attachment" "ecs_execution_policy" {
  role       = aws_iam_role.ecs_execution_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
}

# 自定义策略：明确授予 ECR 拉取所需权限
resource "aws_iam_policy" "ecs_execution_custom_policy" {
  name   = "ecs_execution_custom_policy"
  policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [
      {
        Effect = "Allow",
        Action = [
          "ecr:GetAuthorizationToken",
          "ecr:BatchCheckLayerAvailability",
          "ecr:GetDownloadUrlForLayer",
          "ecr:BatchGetImage"
        ],
        Resource = "*"
      }
    ]
  })
}

resource "aws_iam_role_policy_attachment" "ecs_execution_custom_policy_attachment" {
  role       = aws_iam_role.ecs_execution_role.name
  policy_arn = aws_iam_policy.ecs_execution_custom_policy.arn
}

#############################
# 为 EC2 计算环境创建实例角色 #
#############################
resource "aws_iam_role" "batch_instance_role" {
  name = "batch_instance_role"
  assume_role_policy = jsonencode({
    Version   = "2012-10-17",
    Statement = [{
      Action    = "sts:AssumeRole",
      Effect    = "Allow",
      Principal = { Service = "ec2.amazonaws.com" }
    }]
  })
}

resource "aws_iam_role_policy_attachment" "batch_instance_policy_attachment" {
  role       = aws_iam_role.batch_instance_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonEC2ContainerServiceforEC2Role"
}

resource "aws_iam_instance_profile" "batch_instance_profile" {
  name = "batch_instance_profile"
  role = aws_iam_role.batch_instance_role.name
}

#############################
# 安全组及 VPC 终端节点       #
#############################
resource "aws_security_group" "batch_sg" {
  name        = "batch_sg"
  description = "Security group for AWS Batch compute environment"
  vpc_id      = module.vpc.vpc_id

  ingress {
    from_port   = 0
    to_port     = 65535
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}

# VPC 终端节点：ECR API
resource "aws_vpc_endpoint" "ecr_api" {
  vpc_id            = module.vpc.vpc_id
  service_name      = "com.amazonaws.${var.aws_region}.ecr.api"
  vpc_endpoint_type = "Interface"
  subnet_ids        = module.vpc.subnet_ids
  security_group_ids = [aws_security_group.batch_sg.id]
}

# VPC 终端节点：ECR DKR
resource "aws_vpc_endpoint" "ecr_dkr" {
  vpc_id            = module.vpc.vpc_id
  service_name      = "com.amazonaws.${var.aws_region}.ecr.dkr"
  vpc_endpoint_type = "Interface"
  subnet_ids        = module.vpc.subnet_ids
  security_group_ids = [aws_security_group.batch_sg.id]
}

# VPC 终端节点：S3（Gateway 类型）
resource "aws_vpc_endpoint" "s3" {
  vpc_id            = module.vpc.vpc_id
  service_name      = "com.amazonaws.${var.aws_region}.s3"
  vpc_endpoint_type = "Gateway"
  route_table_ids   = [module.vpc.route_table_ids]
}

#############################
# AWS Batch 资源           #
#############################
# 将 Batch 计算环境改为 EC2 模式，并使用最小实例类型（t3.micro）
resource "aws_batch_compute_environment" "batch_compute_env" {
  compute_environment_name = "batch_compute_env"
  service_role             = aws_iam_role.batch_service_role.arn
  type                     = "MANAGED"

  compute_resources {
    type                = "EC2"
    instance_role       = aws_iam_instance_profile.batch_instance_profile.arn
    instance_types      = ["t3.micro"]
    min_vcpus           = 0
    max_vcpus           = 2
    desired_vcpus       = 0
    subnets             = module.vpc.subnet_ids
    security_group_ids  = [aws_security_group.batch_sg.id]
  }
}

resource "aws_batch_job_queue" "batch_job_queue" {
  name     = var.batch_job_queue_name
  state    = "ENABLED"
  priority = 1

  compute_environment_order {
    order               = 1
    compute_environment = aws_batch_compute_environment.batch_compute_env.arn
  }
}

resource "aws_batch_job_definition" "untar_job_definition" {
  name = var.batch_job_definition_name
  type = "container"

  container_properties = jsonencode({
    image            = "${aws_ecr_repository.untar_repo.repository_url}:latest",
    command          = [
      "python",
      "untar.py",
      "--bucket",
      "Ref::bucket",
      "--files",
      "Ref::files"
    ],
    executionRoleArn = aws_iam_role.ecs_execution_role.arn,
    resourceRequirements = [
      {
        type  = "VCPU",
        value = "1"
      },
      {
        type  = "MEMORY",
        value = "2048"
      }
    ]
  })
   
  parameters = {
    bucket = "",
    files  = ""
  }
}
```

---

### 说明

1. **VPC 模块及随机后缀**  
   用于生成 S3 桶名称和获取 VPC、子网、路由表信息。

2. **S3、ECR 与 Lambda 部分**  
   与之前保持一致，Lambda 触发 S3 事件并调用 Batch 作业。

3. **Batch 相关 IAM**  
   Batch 服务角色、ECS 任务执行角色（附加官方策略及自定义 ECR 权限）保持不变。

4. **EC2 计算环境**  
   新增了 EC2 模型所必需的实例角色（aws_iam_role.batch_instance_role 及实例配置文件 aws_iam_instance_profile.batch_instance_profile），Batch 计算环境中 compute_resources 使用 type = "EC2"，指定 instance_types 为 [ "t3.micro" ]（最小实例类型），并设置最小、最大、期望 vCPU 数量。

5. **Batch 作业定义**  
   保持基本配置（命令、executionRoleArn、资源要求），取消了 Fargate 平台能力配置。

按照以上代码执行后，Batch 作业将使用 EC2 模式运行，使用最小的实例类型来执行作业。执行以下命令进行初始化和部署：

```bash
terraform init
terraform apply
```

这样整个流程就会按照 EC2 模式部署，并满足最低规格要求。
